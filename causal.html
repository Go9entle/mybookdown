<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 格兰格因果性 | 我的研究生课程笔记</title>
  <meta name="description" content="这是用R的bookdown功能制作的课堂笔记。" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="5 格兰格因果性 | 我的研究生课程笔记" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="这是用R的bookdown功能制作的课堂笔记。" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 格兰格因果性 | 我的研究生课程笔记" />
  
  <meta name="twitter:description" content="这是用R的bookdown功能制作的课堂笔记。" />
  

<meta name="author" content="郭镇涛" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="cdc.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX","output/SVG"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
  }
});
</script>
<script type="text/javascript"
   src="../../../MathJax/MathJax.js">
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>写在前面</a></li>
<li class="chapter" data-level="1" data-path="why.html"><a href="why.html"><i class="fa fa-check"></i><b>1</b> 为什么要写课程笔记</a></li>
<li class="chapter" data-level="2" data-path="aboutme.html"><a href="aboutme.html"><i class="fa fa-check"></i><b>2</b> 介绍涛哥</a></li>
<li class="chapter" data-level="3" data-path="usage.html"><a href="usage.html"><i class="fa fa-check"></i><b>3</b> 中文图书Bookdown模板的基本用法</a>
<ul>
<li class="chapter" data-level="3.1" data-path="usage.html"><a href="usage.html#usage-ins"><i class="fa fa-check"></i><b>3.1</b> 安装设置</a></li>
<li class="chapter" data-level="3.2" data-path="usage.html"><a href="usage.html#usage-writing"><i class="fa fa-check"></i><b>3.2</b> 编写自己的内容</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="usage.html"><a href="usage.html#usage-writing-struct"><i class="fa fa-check"></i><b>3.2.1</b> 文档结构</a></li>
<li class="chapter" data-level="3.2.2" data-path="usage.html"><a href="usage.html#usage-writing-fig"><i class="fa fa-check"></i><b>3.2.2</b> 图形自动编号</a></li>
<li class="chapter" data-level="3.2.3" data-path="usage.html"><a href="usage.html#usage-writing-tab"><i class="fa fa-check"></i><b>3.2.3</b> 表格自动编号</a></li>
<li class="chapter" data-level="3.2.4" data-path="usage.html"><a href="usage.html#usage-writing-math"><i class="fa fa-check"></i><b>3.2.4</b> 数学公式编号</a></li>
<li class="chapter" data-level="3.2.5" data-path="usage.html"><a href="usage.html#文献引用与文献列表"><i class="fa fa-check"></i><b>3.2.5</b> 文献引用与文献列表</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="usage.html"><a href="usage.html#usage-output"><i class="fa fa-check"></i><b>3.3</b> 转换</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="usage.html"><a href="usage.html#usage-gitbook"><i class="fa fa-check"></i><b>3.3.1</b> 转换为网页</a></li>
<li class="chapter" data-level="3.3.2" data-path="usage.html"><a href="usage.html#usage-pdfbook"><i class="fa fa-check"></i><b>3.3.2</b> 生成PDF</a></li>
<li class="chapter" data-level="3.3.3" data-path="usage.html"><a href="usage.html#usage-website"><i class="fa fa-check"></i><b>3.3.3</b> 上传到网站</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cdc.html"><a href="cdc.html"><i class="fa fa-check"></i><b>4</b> Optimal strategies for collective defined contribution plans when the stock and labor markets are co-integrated（股票和劳动力市场协同整合时集体确定缴款计划的最优策略）</a>
<ul>
<li class="chapter" data-level="4.1" data-path="cdc.html"><a href="cdc.html#introduction"><i class="fa fa-check"></i><b>4.1</b> 1. Introduction</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="cdc.html"><a href="cdc.html#相关工作"><i class="fa fa-check"></i><b>4.1.1</b> 1.1 相关工作</a></li>
<li class="chapter" data-level="4.1.2" data-path="cdc.html"><a href="cdc.html#主要区别"><i class="fa fa-check"></i><b>4.1.2</b> 2.1 主要区别</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="cdc.html"><a href="cdc.html#模型的公式化"><i class="fa fa-check"></i><b>4.2</b> 2 模型的公式化</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="cdc.html"><a href="cdc.html#金融市场"><i class="fa fa-check"></i><b>4.2.1</b> 2.1 金融市场</a></li>
<li class="chapter" data-level="4.2.2" data-path="cdc.html"><a href="cdc.html#劳动收入"><i class="fa fa-check"></i><b>4.2.2</b> 2.2 劳动收入</a></li>
<li class="chapter" data-level="4.2.3" data-path="cdc.html"><a href="cdc.html#养老金系统"><i class="fa fa-check"></i><b>4.2.3</b> 2.3 养老金系统</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="cdc.html"><a href="cdc.html#养老金基金计划的最优策略"><i class="fa fa-check"></i><b>4.3</b> 3 养老金基金计划的最优策略</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="cdc.html"><a href="cdc.html#具有特质性冲击的最优策略"><i class="fa fa-check"></i><b>4.3.1</b> 3.1 具有特质性冲击的最优策略</a></li>
<li class="chapter" data-level="4.3.2" data-path="cdc.html"><a href="cdc.html#无特质性冲击时的最优策略"><i class="fa fa-check"></i><b>4.3.2</b> 3.2 无特质性冲击时的最优策略</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="cdc.html"><a href="cdc.html#数值分析"><i class="fa fa-check"></i><b>4.4</b> 4 数值分析</a></li>
<li class="chapter" data-level="4.5" data-path="cdc.html"><a href="cdc.html#总结"><i class="fa fa-check"></i><b>4.5</b> 5 总结</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="causal.html"><a href="causal.html"><i class="fa fa-check"></i><b>5</b> 格兰格因果性</a>
<ul>
<li class="chapter" data-level="5.1" data-path="causal.html"><a href="causal.html#causal-intro"><i class="fa fa-check"></i><b>5.1</b> 介绍</a></li>
<li class="chapter" data-level="5.2" data-path="causal.html"><a href="causal.html#causal-def"><i class="fa fa-check"></i><b>5.2</b> 格兰格因果性的定义</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="causal.html"><a href="causal.html#过程中的状态概念"><i class="fa fa-check"></i><b>5.2.1</b> 过程中的状态概念</a></li>
<li class="chapter" data-level="5.2.2" data-path="causal.html"><a href="causal.html#通过股票价格的例子理解markov性"><i class="fa fa-check"></i><b>5.2.2</b> 通过股票价格的例子理解Markov性</a></li>
<li class="chapter" data-level="5.2.3" data-path="causal.html"><a href="causal.html#markov过程的正式定义"><i class="fa fa-check"></i><b>5.2.3</b> Markov过程的正式定义</a></li>
<li class="chapter" data-level="5.2.4" data-path="causal.html"><a href="causal.html#markov过程的稳态分布"><i class="fa fa-check"></i><b>5.2.4</b> Markov过程的稳态分布</a></li>
<li class="chapter" data-level="5.2.5" data-path="causal.html"><a href="causal.html#markov奖励过程的形式主义"><i class="fa fa-check"></i><b>5.2.5</b> Markov奖励过程的形式主义</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">我的研究生课程笔记</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="causal" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> 格兰格因果性<a href="causal.html#causal" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="causal-intro" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> 介绍<a href="causal.html#causal-intro" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>考虑两个时间序列之间的因果性。
这里的因果性指的是时间顺序上的关系，
如果<span class="math inline">\(X_{t-1}, X_{t-2}, \dots\)</span>对<span class="math inline">\(Y_t\)</span>有作用，
而<span class="math inline">\(Y_{t-1}, Y_{t-2}, \dots\)</span>对<span class="math inline">\(X_t\)</span>没有作用，
则称<span class="math inline">\(\{X_t \}\)</span>是<span class="math inline">\(\{ Y_t \}\)</span>的格兰格原因，
而<span class="math inline">\(\{ Y_t \}\)</span>不是<span class="math inline">\(\{ X_t \}\)</span>的格兰格原因。
如果<span class="math inline">\(X_{t-1}, X_{t-2}, \dots\)</span>对<span class="math inline">\(Y_t\)</span>有作用，
<span class="math inline">\(Y_{t-1}, Y_{t-2}, \dots\)</span>对<span class="math inline">\(X_t\)</span>也有作用，
则在没有进一步信息的情况下无法确定两个时间序列的因果性关系。</p>
<p>注意这种因果性与采样频率有关系，
在日数据或者月度数据中能发现的领先——滞后性质的因果关系，
到年度数据可能就以及混杂在以前变成同步的关系了。</p>
</div>
<div id="causal-def" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> 格兰格因果性的定义<a href="causal.html#causal-def" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>设<span class="math inline">\(\{ \xi_t \}\)</span>为一个时间序列，
<span class="math inline">\(\{ \boldsymbol{\eta}_t \}\)</span>为向量时间序列，
记
<span class="math display">\[\begin{aligned}
\bar{\boldsymbol{\eta}}_t =&amp; \{ \boldsymbol{\eta}_{t-1}, \boldsymbol{\eta}_{t-2}, \dots \}
\end{aligned}\]</span></p>
<p>记
<span class="math inline">\(\text{Pred}(\xi_t | \bar{\boldsymbol{\eta}}_t)\)</span>为基于
<span class="math inline">\(\boldsymbol{\eta}_{t-1}, \boldsymbol{\eta}_{t-2}, \dots\)</span>
对<span class="math inline">\(\xi_t\)</span>作的最小均方误差无偏预报，
其解为条件数学期望<span class="math inline">\(E(\xi_t | \boldsymbol{\eta}_{t-1}, \boldsymbol{\eta}_{t-2}, \dots)\)</span>，
在一定条件下可以等于<span class="math inline">\(\xi_t\)</span>在<span class="math inline">\(\boldsymbol{\eta}_{t-1}, \boldsymbol{\eta}_{t-2}, \dots\)</span>张成的线性Hilbert空间的投影
（比如，<span class="math inline">\((\xi_t, \boldsymbol{\eta}_t)\)</span>为平稳正态多元时间序列），
即最优线性预测。
直观理解成基于过去的<span class="math inline">\(\{\boldsymbol{\eta}_{t-1}, \boldsymbol{\eta}_{t-2}, \dots \}\)</span>的信息对当前的<span class="math inline">\(\xi_t\)</span>作的最优预测。</p>
<p>令一步预测误差为
<span class="math display">\[
  \varepsilon(\xi_t | \bar{\boldsymbol{\eta}}_t)
  = \xi_t - \text{Pred}(\xi_t | \bar{\boldsymbol{\eta}}_t)
\]</span>
令一步预测误差方差，或者均方误差，
为
<span class="math display">\[
  \sigma^2(\xi_t | \bar{\boldsymbol{\eta}}_t)  
  = \text{Var}(\varepsilon_t(\xi_t | \bar{\boldsymbol{\eta}}_t) )
  = E \left[ \xi_t - \text{Pred}(\xi_t | \bar{\boldsymbol{\eta}}_t) \right]^2
\]</span></p>
<p>考虑两个时间序列<span class="math inline">\(\{ X_t \}\)</span>和<span class="math inline">\(\{ Y_t \}\)</span>，
<span class="math inline">\(\{(X_t, Y_t) \}\)</span>宽平稳或严平稳。</p>
<ul>
<li>如果
<span class="math display">\[
\sigma^2(Y_t | \bar Y_t, \bar X_t) &lt; \sigma^2(Y_t | \bar Y_t)
\]</span>
则称<span class="math inline">\(\{ X_t \}\)</span>是<span class="math inline">\(\{ Y_t \}\)</span>的<strong>格兰格原因</strong>，
记作<span class="math inline">\(X_t \Rightarrow Y_t\)</span>。
这不排除<span class="math inline">\(\{ Y_t \}\)</span>也可以是<span class="math inline">\(\{ X_t \}\)</span>的格兰格原因。</li>
<li>如果<span class="math inline">\(X_t \Rightarrow Y_t\)</span>，而且<span class="math inline">\(Y_t \Rightarrow X_t\)</span>，
则称互相有<strong>反馈</strong>关系，
记作<span class="math inline">\(X_t \Leftrightarrow Y_t\)</span>。</li>
<li>如果
<span class="math display">\[
\sigma^2(Y_t | \bar Y_t, X_t, \bar X_t) &lt; \sigma^2(Y_t | \bar Y_t, \bar X_t)
\]</span>
即除了过去的信息，
增加同时刻的<span class="math inline">\(X_t\)</span>信息后对<span class="math inline">\(Y_t\)</span>预测有改进，
则称<span class="math inline">\(\{X_t \}\)</span>对<span class="math inline">\(\{Y_t \}\)</span>有瞬时因果性。
这时<span class="math inline">\(\{Y_t \}\)</span>对<span class="math inline">\(\{X_t \}\)</span>也有瞬时因果性。</li>
<li>如果<span class="math inline">\(X_t \Rightarrow Y_t\)</span>，
则存在最小的正整数<span class="math inline">\(m\)</span>，
使得
<span class="math display">\[
\sigma^2(Y_t | \bar Y_t, X_{t-m}, X_{t-m-1}, \dots)
&lt; \sigma^2(Y_t | \bar Y_t, X_{t-m-1}, X_{t-m-2}, \dots)
\]</span>
称<span class="math inline">\(m\)</span>为<strong>因果性滞后值</strong>(causality lag)。
如果<span class="math inline">\(m&gt;1\)</span>，
这意味着在已有<span class="math inline">\(Y_{t-1}, Y_{t-2}, \dots\)</span>和<span class="math inline">\(X_{t-m}, X_{t-m-1}, \dots\)</span>的条件下，
增加<span class="math inline">\(X_{t-1}\)</span>, , <span class="math inline">\(X_{t-m+1}\)</span>不能改进对<span class="math inline">\(Y_t\)</span>的预测。</li>
</ul>
<div class="example">
<p><span id="exm:causal-exaxylag1" class="example"><strong>例5.1  </strong></span>设<span class="math inline">\(\{ \varepsilon_t, \eta_t \}\)</span>是相互独立的零均值白噪声列，
<span class="math inline">\(\text{Var}(\varepsilon_t)=1\)</span>,
<span class="math inline">\(\text{Var}(\eta_t)=1\)</span>,
考虑
<span class="math display">\[\begin{aligned}
Y_t =&amp; X_{t-1} + \varepsilon_t \\
X_t =&amp; \eta_t + 0.5 \eta_{t-1}
\end{aligned}\]</span></p>
</div>
<p>用<span class="math inline">\(L(\cdot|\cdot)\)</span>表示最优线性预测，则
<span class="math display">\[\begin{aligned}
&amp; L(Y_t | \bar Y_t, \bar X_t) \\
=&amp; L(X_{t-1} | X_{t-1}, \dots, Y_{t-1}, \dots)
+ L(\varepsilon_t | \bar Y_t, \bar X_t) \\
=&amp; X_{t-1} + 0 \\
=&amp; X_{t-1} \\
\sigma(Y_t | \bar Y_t, \bar X_t) =&amp;
\text{Var}(\varepsilon_t) = 1
\end{aligned}\]</span>
而
<span class="math display">\[
Y_t = \eta_{t-1} + 0.5\eta_{t-2} + \varepsilon_t
\]</span>
有
<span class="math display">\[\begin{aligned}
\gamma_Y(0) = 2.25,
\gamma_Y(1) = 0.5,
\gamma_Y(k) = 0, k \geq 2
\end{aligned}\]</span>
所以<span class="math inline">\(\{Y_t \}\)</span>是一个MA(1)序列，
设其方程为
<span class="math display">\[
Y_t = \zeta_t + b \zeta_{t-1},
\zeta_t \sim \text{WN}(0, \sigma_\zeta^2)
\]</span>
可以解出
<span class="math display">\[\begin{aligned}
\rho_Y(1) =&amp; \frac{\gamma_Y(1)}{\gamma_Y(0)} = \frac{2}{9} \\
b =&amp; \frac{1 - \sqrt{1 - 4 \rho_Y^2(1)}}{2 \rho_Y(1)}
\approx 0.2344 \\
\sigma_\zeta^2 =&amp; \frac{\gamma_Y(1)}{b} \approx 2.1328
\end{aligned}\]</span>
于是
<span class="math display">\[\begin{aligned}
\sigma(Y_t | \bar Y_t)
=&amp; \sigma_\zeta^2 = 2.1328
\end{aligned}\]</span>
所以
<span class="math display">\[\begin{aligned}
\sigma(Y_t | \bar Y_t, \bar X_t) = 1
&lt; 2.1328 = \sigma(Y_t | \bar Y_t)
\end{aligned}\]</span>
即<span class="math inline">\(X_t\)</span>是<span class="math inline">\(Y_t\)</span>的格兰格原因。</p>
<p>反之，
<span class="math inline">\(X_t\)</span>是MA(1)序列，
有
<span class="math display">\[
\eta_t = \frac{1}{1 + 0.5 B} X_t
= \sum_{j=0}^\infty (-0.5)^j X_{t-j}
\]</span>
其中<span class="math inline">\(B\)</span>是推移算子（滞后算子）。
于是
<span class="math display">\[\begin{aligned}
L(X_t | \bar X_t)
=&amp; L(\eta_t | \bar X_t)
+ 0.5 L(\eta_{t-1} | \bar X_t) \\
=&amp; 0.5 \sum_{j=0}^\infty (-0.5)^j X_{t-1-j} \\
=&amp; - \sum_{j=1}^\infty (-0.5)^j X_{t-j} \\
\sigma(X_t | \bar X_t)
=&amp; \text{Var}(X_t - L(X_t | \bar X_t)) \\
=&amp; \text{Var}(\eta_t) = 1
\end{aligned}\]</span>
而
<span class="math display">\[\begin{aligned}
L(X_t | \bar X_t, \bar Y_t)
=&amp; L(\eta_t | \bar X_t, \bar Y_t)
+ 0.5 L(\eta_{t-1} | \bar X_t, \bar Y_t) \\
=&amp; 0 +
0.5 L(\sum_{j=0}^\infty (-0.5)^j X_{t-1-j} | \bar X_t, \bar Y_t) \\
=&amp; -\sum_{j=1}^\infty (-0.5)^j X_{t-j} \\
=&amp; L(X_t | \bar X_t)
\end{aligned}\]</span>
所以<span class="math inline">\(Y_t\)</span>不是<span class="math inline">\(X_t\)</span>的格兰格原因。</p>
<p>考虑瞬时因果性。
<span class="math display">\[\begin{aligned}
L(Y_t | \bar X_t, \bar Y_t, X_t)
=&amp; X_{t-1} + 0 (\text{注意}\varepsilon_t\text{与}\{X_s, \forall s\}\text{不相关} \\
=&amp; L(Y_t | \bar X_t, \bar Y_t)
\end{aligned}\]</span>
所以<span class="math inline">\(X_t\)</span>不是<span class="math inline">\(Y_t\)</span>的瞬时格兰格原因。</p>
<p>○○○○○</p>
<div class="example">
<p><span id="exm:causal-exaxylag2" class="example"><strong>例5.2  </strong></span>在例<a href="causal.html#exm:causal-exaxylag1">5.1</a>中，如果模型改成
<span class="math display">\[\begin{aligned}
Y_t =&amp; X_{t} + \varepsilon_t \\
X_t =&amp; \eta_t + 0.5 \eta_{t-1}
\end{aligned}\]</span>
有怎样的结果？</p>
</div>
<p>这时
<span class="math display">\[
Y_t = \varepsilon_t + \eta_t + 0.5 \eta_{t-1}
\]</span>
仍有
<span class="math display">\[\begin{aligned}
\gamma_Y(0) = 2.25,
\gamma_Y(1) = 0.5,
\gamma_Y(k) = 0, k \geq 2
\end{aligned}\]</span>
所以<span class="math inline">\(Y_t\)</span>还服从MA(1)模型
<span class="math display">\[
Y_t = \zeta_t + b \zeta_{t-1},
b \approx 0.2344,
\sigma^2_\zeta \approx 2.1328
\]</span></p>
<p><span class="math display">\[\begin{aligned}
L(Y_t | \bar Y_t, \bar X_t)
=&amp; L(X_t | \bar Y_t, \bar X_t) + 0 \\
=&amp; L(\eta_t | \bar Y_t, \bar X_t)
+ 0.5 L(\eta_{t-1} | \bar Y_t, \bar X_t) \\
=&amp; 0 + 0.5 L(\sum_{j=0}^\infty (-0.5)^j X_{t-1-j} | \bar Y_t, \bar X_t) \\
=&amp; - \sum_{j=1}^\infty (-0.5)^j X_{t-j} \\
=&amp; X_t - \eta_t \\
\sigma(Y_t | \bar Y_t, \bar X_t)
=&amp; \text{Var}(\varepsilon_t + \eta_t) = 2
\end{aligned}\]</span>
而
<span class="math display">\[
\sigma(Y_t | \bar Y_t)
= \sigma^2_\zeta \approx 2.1328
&gt; \sigma(Y_t | \bar Y_t, \bar X_t) = 2
\]</span>
所以<span class="math inline">\(X_t\)</span>是<span class="math inline">\(Y_t\)</span>的格兰格原因。</p>
<p>反之，
<span class="math display">\[\begin{aligned}
L(X_t | \bar X_t, \bar Y_t)
=&amp; - \sum_{j=1}^\infty (-0.5)^j X_{t-j} \\
=&amp; L(X_t | \bar X_t)
\end{aligned}\]</span>
所以<span class="math inline">\(Y_t\)</span>不是<span class="math inline">\(X_t\)</span>的格兰格原因。</p>
<p>考虑瞬时因果性。
<span class="math display">\[\begin{aligned}
L(Y_t | \bar X_t, \bar Y_t, X_t)
=&amp; X_{t} + 0 (\text{注意}\varepsilon_t\text{与}\{X_s, \forall s\}\text{不相关} \\
=&amp; X_t \\
\sigma(Y_t | \bar X_t, \bar Y_t, X_t)
=&amp; \text{Var}(\varepsilon) \\
=&amp; 1 &lt; 2 = \sigma(Y_t | \bar X_t, \bar Y_t)
\end{aligned}\]</span>
所以<span class="math inline">\(X_t\)</span>是<span class="math inline">\(Y_t\)</span>的瞬时格兰格原因。</p>
<p><span class="math display">\[\begin{aligned}
[aaa]
\end{aligned}\]</span></p>

<p>#强化学习在金融中的应用
## Markov过程 {#Markov}</p>
<p>本书的主题是“序列不确定下的序列决策”，在本章中将暂时忽略“序列决策”方面而只关注”序列不确定性“。</p>
<div id="过程中的状态概念" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> 过程中的状态概念<a href="causal.html#过程中的状态概念" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math inline">\(S_t\)</span>是过程在时间<span class="math inline">\(t\)</span>时的状态。特别地，我们对于下一时刻的状态<span class="math inline">\(S_{t+1}\)</span>的概率感兴趣，如果已知现在的状态<span class="math inline">\(S_t\)</span>和过去的状态<span class="math inline">\(S_0,S_1,...,S_{t-1}\)</span>，我们对<span class="math inline">\(P\{S_{t+1}|S_t,S_{t-1},...,S_0\}\)</span>感兴趣。</p>
</div>
<div id="通过股票价格的例子理解markov性" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> 通过股票价格的例子理解Markov性<a href="causal.html#通过股票价格的例子理解markov性" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>为了帮助理解，我们假设股票价格只取整数值，并且零或负股票价格是可以接受的。我们将时间<span class="math inline">\(t\)</span>的股票价格表示为<span class="math inline">\(X_t\)</span>.假设从时间<span class="math inline">\(t\)</span> 到下一个时间步骤 <span class="math inline">\(t + 1\)</span>,股票价格可以上涨<span class="math inline">\(1\)</span>或下跌<span class="math inline">\(1\)</span>,即<span class="math inline">\(X_{t+1}\)</span>的唯一两个结果是<span class="math inline">\(X_t + 1\)</span>或<span class="math inline">\(X_t − 1\)</span>.要了解股票价格随时间的随机演变，我们只需要量化上涨的概率 <span class="math inline">\(P[X_{t+1} =X_t+ 1]\)</span>.我们将考虑股票价格演变的 3 个不同过程。</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(P[X_{t+1}=X_t+1]=\frac{1}{1+e^{-\alpha_1(L-X_t)}}\)</span>.</p>
<p>这意味着股票的价格倾向于均值回归(mean-reverting),均值即为参考水平<span class="math inline">\(L,\)</span>拉力系数为<span class="math inline">\(\alpha.\)</span></p>
<p>我们不妨设<span class="math inline">\(S_t=X_t,\)</span>且可以看到下一时刻的状态<span class="math inline">\(S_{t+1}\)</span>只与<span class="math inline">\(S_t\)</span>有关而与<span class="math inline">\(S_0,S_1,...,S_{t-1}\)</span>无关。即可写作
<span class="math display">\[
P[S_{t+1}|S_t,S_{t-1},...,S_0]=P[S_{t+1}|S_t]\text{ for all }t\geq 0.
\]</span>
这就被成为Markov性。</p>
<p>书中还给出了相应的代码</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="causal.html#cb9-1" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb9-2"><a href="causal.html#cb9-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-3"><a href="causal.html#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="causal.html#cb9-4" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb9-5"><a href="causal.html#cb9-5" tabindex="-1"></a><span class="kw">class</span> Process1:</span>
<span id="cb9-6"><a href="causal.html#cb9-6" tabindex="-1"></a>    <span class="at">@dataclass</span></span>
<span id="cb9-7"><a href="causal.html#cb9-7" tabindex="-1"></a>    <span class="kw">class</span> State:</span>
<span id="cb9-8"><a href="causal.html#cb9-8" tabindex="-1"></a>        price: <span class="bu">int</span></span>
<span id="cb9-9"><a href="causal.html#cb9-9" tabindex="-1"></a></span>
<span id="cb9-10"><a href="causal.html#cb9-10" tabindex="-1"></a>    level_param: <span class="bu">int</span>  <span class="co"># level to which price mean-reverts</span></span>
<span id="cb9-11"><a href="causal.html#cb9-11" tabindex="-1"></a>    alpha1: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.25</span>  <span class="co"># strength of mean-reversion (non-negative value)</span></span>
<span id="cb9-12"><a href="causal.html#cb9-12" tabindex="-1"></a></span>
<span id="cb9-13"><a href="causal.html#cb9-13" tabindex="-1"></a>    <span class="kw">def</span> up_prob(<span class="va">self</span>, state: State) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb9-14"><a href="causal.html#cb9-14" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1.</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(<span class="op">-</span><span class="va">self</span>.alpha1<span class="op">*</span>(<span class="va">self</span>.level_param<span class="op">-</span>state.price)))</span>
<span id="cb9-15"><a href="causal.html#cb9-15" tabindex="-1"></a>    <span class="kw">def</span> next_state(<span class="va">self</span>, state:State) <span class="op">-&gt;</span> State:</span>
<span id="cb9-16"><a href="causal.html#cb9-16" tabindex="-1"></a>        up_move: <span class="bu">int</span> <span class="op">=</span> np.random.binomial(<span class="dv">1</span>, <span class="va">self</span>.up_prob(state),<span class="dv">1</span>)[<span class="dv">0</span>] <span class="co">#生成随机移动 up_move = 0 or 1</span></span>
<span id="cb9-17"><a href="causal.html#cb9-17" tabindex="-1"></a>        <span class="cf">return</span> Process1.State(price<span class="op">=</span>state.price <span class="op">+</span> up_move <span class="op">*</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span>) <span class="co"># 若up_move = 1, 则价格上升1，若为0价格下降1</span></span></code></pre></div>
<p>接下来，我们使用 Python 的生成器功能（使用<code>yield</code>）编写一个简单的模拟器，如下所示：</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="causal.html#cb10-1" tabindex="-1"></a><span class="kw">def</span> simulation(process, start_state):</span>
<span id="cb10-2"><a href="causal.html#cb10-2" tabindex="-1"></a>    state <span class="op">=</span> start_state</span>
<span id="cb10-3"><a href="causal.html#cb10-3" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb10-4"><a href="causal.html#cb10-4" tabindex="-1"></a>        <span class="cf">yield</span> state</span>
<span id="cb10-5"><a href="causal.html#cb10-5" tabindex="-1"></a>        state <span class="op">=</span> process.next_state(state)</span></code></pre></div>
<p>现在我们可以使用此模拟器函数生成采样轨迹。在下面的代码中，我们从 <code>start_price</code>的价格<span class="math inline">\(X_0\)</span>​开始，在<code>time_steps</code>时间步长内生成<code>num_traces</code>个采样轨迹。使用 Python 的生成器功能，我们可以使用<code>itertools.islice</code>函数“懒惰地”执行此操作。</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="causal.html#cb11-1" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb11-2"><a href="causal.html#cb11-2" tabindex="-1"></a><span class="kw">def</span> process1_price_traces(</span>
<span id="cb11-3"><a href="causal.html#cb11-3" tabindex="-1"></a> start_price: <span class="bu">int</span>,</span>
<span id="cb11-4"><a href="causal.html#cb11-4" tabindex="-1"></a>    level_param: <span class="bu">int</span>,</span>
<span id="cb11-5"><a href="causal.html#cb11-5" tabindex="-1"></a>    alpha1: <span class="bu">float</span>,</span>
<span id="cb11-6"><a href="causal.html#cb11-6" tabindex="-1"></a>    time_steps: <span class="bu">int</span>,</span>
<span id="cb11-7"><a href="causal.html#cb11-7" tabindex="-1"></a>    num_traces: <span class="bu">int</span></span>
<span id="cb11-8"><a href="causal.html#cb11-8" tabindex="-1"></a>) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb11-9"><a href="causal.html#cb11-9" tabindex="-1"></a>    process <span class="op">=</span> Process1(level_param<span class="op">=</span>level_param, alpha1<span class="op">=</span>alpha1)</span>
<span id="cb11-10"><a href="causal.html#cb11-10" tabindex="-1"></a>    start_state <span class="op">=</span> Process1.State(price<span class="op">=</span>start.price)</span>
<span id="cb11-11"><a href="causal.html#cb11-11" tabindex="-1"></a>    <span class="cf">return</span> np.vstack([</span>
<span id="cb11-12"><a href="causal.html#cb11-12" tabindex="-1"></a>        np.fromiter((s.price <span class="cf">for</span> s <span class="kw">in</span> itertools.islice(</span>
<span id="cb11-13"><a href="causal.html#cb11-13" tabindex="-1"></a>         simulation(process, start_state),</span>
<span id="cb11-14"><a href="causal.html#cb11-14" tabindex="-1"></a>            time_steps <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-15"><a href="causal.html#cb11-15" tabindex="-1"></a>     )), <span class="bu">float</span>) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_traces)])</span></code></pre></div></li>
<li><p><span class="math display">\[
P[X_{t+1}=X_t+1]=\begin{cases}
0.5(1-\alpha_2(X_t-X_{t-1}))&amp;\text{  if }t&gt;0\\
0.5&amp;\text{ if }t=0
\end{cases}
\]</span></p>
<p>其中<span class="math inline">\(\alpha_2\)</span>是一个“拉力强度”参数，取值在<span class="math inline">\([0,1]\)</span>之间。这里的直觉时下一步的移动的方向偏向于前一次移动的反方向。我们注意到如果依然按照前文建模则无法满足Markov性质，因为<span class="math inline">\(X_{t+1}\)</span>取值的概率不仅依赖于<span class="math inline">\(X_t,\)</span>还依赖于<span class="math inline">\(X_{t-1}.\)</span>不过我们可以在这里做一个小技巧，即创建一个扩展状态<span class="math inline">\(S_t\)</span>由一对<span class="math inline">\((X_t,X_{t-1})\)</span>组成。当<span class="math inline">\(t=0\)</span>时状态<span class="math inline">\(S_0\)</span>可以取值<span class="math inline">\((X_0,null)\)</span>,这里的null只是一个符号。通过将状态<span class="math inline">\(S_t\)</span>视为<span class="math inline">\((X_t,X_t-X_{t-1})\)</span>建模可以发现Markov性质得到了满足。
<span class="math display">\[
\begin{aligned}
&amp;P[(X_{t+1},X_{t+1}-X_t)|(X_t,X_t-X_{t-1}),...,(X_0,null)]\\
=&amp;P[(X_{t+1},X_{t+1}-X_t)|(X_t,X_t-X_{t-1})]\\
=&amp;0.5(1-\alpha_2(X_{t+1}-X_t)(X_t-X_{t-1}))
\end{aligned}
\]</span>
关于上面的式子deepseek给出了证明。</p>
<p>人们自然会想知道，为什么状态不单单由<span class="math inline">\(X_t - X_{t-1}\)</span> 组成——换句话说，为什么 <span class="math inline">\(X_t\)</span> 也需要作为状态的一部分。确实，单独知道<span class="math inline">\(X_t - X_{t-1}\)</span>可以完全确定 <span class="math inline">\(X_{t+1}-X_t\)</span>的概率。因此，如果我们将状态设定为在任意时间步 <span class="math inline">\(t\)</span>仅为 <span class="math inline">\(X_t - X_{t-1}\)</span>，那么我们确实会得到一个只有两个状态 +1 和 -1 的马尔可夫过程（它们之间的概率转移）。然而，这个简单的马尔可夫过程并不能通过查看时间<span class="math inline">\(t\)</span>的状态 <span class="math inline">\(X_t - X_{t-1}\)</span> 来告诉我们股票价格 <span class="math inline">\(X_t\)</span> 的值。在这个应用中，我们不仅关心马尔可夫状态转移概率，还关心从时间 <span class="math inline">\(t\)</span> 的状态中获取任意时间 <span class="math inline">\(t\)</span> 的股票价格信息。因此，我们将状态建模为对 <span class="math inline">\(( X_t, X_{t-1} )\)</span>。</p>
<p>请注意，如果我们将状态 <span class="math inline">\(S_t\)</span> 建模为整个股票价格历史 <span class="math inline">\(( X_0, X_1,..., X_t )，\)</span>那么马尔可夫性质将显然得到满足，将<span class="math inline">\(S_t\)</span>建模为对<span class="math inline">\((X_t,X_{t-1})\)</span>Markov性质也会得到满足。然而，我们选择 <span class="math inline">\(S_t := (X_t, X_t - X_{t-1})\)</span> 是“最简单”的内部表示。实际上，在整本书中，我们对各种过程建模状态的努力是确保马尔可夫性质，同时使用“最简单/最小”的状态表示。</p></li>
<li><p>Process3是Process2的扩展，其中下一个移动的概率不仅依赖于上一时刻的移动还依赖于过去所有的移动。具体来说，它依赖于过去上涨次数的数量记为<span class="math inline">\(U_t=\sum_{i=1}^t\max(X_i-X_{i-1},0)\)</span>,与过去下跌次数的数量，记为<span class="math inline">\(D_t=\sum_{i=1}^t\max(X_{i-1}-X_i,0)\)</span>之间的关系。表示为
<span class="math display">\[
P[X_{t+1}=X_t+1]=\begin{cases}
\frac{1}{1+(\frac{U_t+D_t}{D_t}-1)^{\alpha_3}}&amp;\text{ if }t&gt;0\\
0.5&amp;\text{ if }t=0
\end{cases}
\]</span>
其中<span class="math inline">\(\alpha_3\in\mathbb{R}_{\geq0}\)</span>是一个拉力强度参数，将上述概率表达式视为<span class="math inline">\(f(\frac{D_t}{U_t+D_t};\alpha_3)\)</span>其中<span class="math inline">\(f:[0,1]\rightarrow[0,1]\)</span>是一个sigmoid型函数
<span class="math display">\[
f(x;\alpha)=\frac{1}{1+(\frac{1}{x}-1)^{\alpha}}.
\]</span>
下一个上涨移动的概率基本依赖<span class="math inline">\(\frac{U_t}{U_t+D_t}\)</span>即过去时间步中下跌次数的比例。因此，如果历史上的下跌次数大于上涨次数，那么下一个价格移动<span class="math inline">\(X_{t+1}-X_t\)</span>将会有更多的向上拉力，反之亦然。</p>
<p>我们将<span class="math inline">\(S_t\)</span>建模为由对<span class="math inline">\((U_t,D_t)\)</span>组成，这样<span class="math inline">\(S_t\)</span>的Markov性质可以得到满足
<span class="math display">\[
\begin{aligned}
&amp;P[(U_{t+1},D_{t+1})|(U_t,D_t),...,(U_0,D_0)]=P[(U_{t+1},D_{t+1})|(U_t,D_t)]\\
&amp;=\begin{cases}
f(\frac{D_t}{U_t+D_t};\alpha_3)&amp;\text{ if }U_{t+1}=U_t+1,D_{t+1}=D_t\\
f(\frac{U_t}{U_t+D_t};\alpha_3)&amp;\text{ if }U_{t+1}=U_t,D_{t+1}=D_t+1
\end{cases}
\end{aligned}
\]</span>
重要的是与前面两个过程不同，股票价格<span class="math inline">\(X_t\)</span>实际上并不是过程3中状态<span class="math inline">\(S_t\)</span>的一部分，这是因为<span class="math inline">\(U_t,D_t\)</span>共同包含了捕捉<span class="math inline">\(X_t\)</span>的足够信息，因为<span class="math inline">\(X_t=X_0+U_t-D_t.\)</span></p></li>
</ol>
</div>
<div id="markov过程的正式定义" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Markov过程的正式定义<a href="causal.html#markov过程的正式定义" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>书中的定义和定理将由限制在离散时间和可数状态集合。</p>
<blockquote>
<p><strong>Def 3.3.1</strong></p>
<p>Markov过程由以下组成</p>
<ul>
<li>一个可数状态集合<span class="math inline">\(\mathcal{S}\)</span>（称为状态空间）和一个子集<span class="math inline">\(\mathcal{T}\subset \mathcal{S}\)</span>​（称为终止状态集合）。</li>
<li>一个时间索引的随即状态序列<span class="math inline">\(S_t\in S,\)</span>时间步为<span class="math inline">\(t=0,1,2,...\)</span>,每个状态转移都满足Markov性质:<span class="math inline">\(P[S_{t+1}|S_t,...,S_0]=P[S_{t+1}|S_t],\text{for all }t\geq0.\)</span></li>
<li>终止：如果某个时间步<span class="math inline">\(T\)</span>的结果<span class="math inline">\(S_T\)</span>是集合<span class="math inline">\(\mathcal{T}\)</span>中的一个状态，则该序列的结果在时间步<span class="math inline">\(T\)</span>终止。</li>
</ul>
<p>将<span class="math inline">\(P[S_{t+1}|S_t]\)</span>称为时间<span class="math inline">\(t\)</span>的转移概率。</p>
<p><strong>Def 3.3.2</strong></p>
<p>一个时间齐次Markov过程是一个Markov过程且<span class="math inline">\(P[S_{t+1}|S_t]\)</span>与<span class="math inline">\(t\)</span>无关。</p>
</blockquote>
<p>这意味着时间齐次Markov过程的动态可以通过下面的函数完全指定：
<span class="math display">\[
P:(\mathcal{S}-\mathcal{T})\times\mathcal{S}\rightarrow[0,1]
\]</span>
定义为<span class="math inline">\(P(s&#39;,s)=P[S_{t+1}=s&#39;|S_t=s]\)</span>使得<span class="math inline">\(\sum_{s&#39;\in S}P(s,s&#39;)=1,\text{for all}s\in\mathcal{S-T}.\)</span>​</p>
<p>注意上述规范中<span class="math inline">\(P\)</span>的参数没有时间索引<span class="math inline">\(t\)</span>（因此称为时间齐次）。此外注意到一个非时间齐次的Markov过程可以通过将所有状态和时间索引<span class="math inline">\(t\)</span>来结合转换为齐次Markov过程。这意味着如果一个非时间齐次的Markov过程的原始状态空间是<span class="math inline">\(\mathcal{S}\)</span>，那么对应的时间齐次Markov过程的状态空间是<span class="math inline">\(\mathbb{Z}_{\geq0}\times\mathcal{S}.\)</span></p>
</div>
<div id="markov过程的稳态分布" class="section level3 hasAnchor" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Markov过程的稳态分布<a href="causal.html#markov过程的稳态分布" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p><strong>Def 3.7.1</strong>
对于状态空间<span class="math inline">\(\mathcal{S}=\mathbb{N}\)</span>的离散、时间齐次的Markov过程及其转移概率函数<span class="math inline">\(P:\mathbb{N}\times\mathbb{N}\rightarrow [0,1]\)</span>,稳态分布是一个概率分布函数<span class="math inline">\(\pi:\mathbb{N}\rightarrow [0,1]\)</span>,满足
<span class="math display">\[
\pi(s&#39;)=\sum_{s\in\mathbb{N}}\pi(s)\cdot P(s,s&#39;),\text{ for all }s&#39;\in\mathbb{N}
\]</span></p>
</blockquote>
<p>稳态分布<span class="math inline">\(\pi\)</span>的直观理解是，在特定条件下如果我们让Markov过程无限运行，那么在长期内，状态在特定步出现频率（概率）由分布<span class="math inline">\(\pi\)</span>给出，该分布与时间步无关。</p>
<p>如果将稳态分布的定义专门化为有限状态、离散时间、时间齐次的Markov过程，状态空间为<span class="math inline">\(S=\{s_1,...,s_2\}=\mathbb{N},\)</span>那么我们可以将稳态分布<span class="math inline">\(\pi\)</span>​表示为
<span class="math display">\[
\pi(s_j)=\sum_{i=1}^n\pi(s_i)\cdot P(s_i,s_j),\text{ for al }j=1,2,...,n
\]</span>
下面使用粗体符号表示向量和矩阵。故<span class="math inline">\(\boldsymbol{\pi}\)</span>是一个长度为<span class="math inline">\(n\)</span>的列向量，<span class="math inline">\(\boldsymbol{\mathcal{P}}\)</span>是<span class="math inline">\(n\times n\)</span>的转移概率矩阵，其中行是原状态，列为目标状态，每行的和为1。那么上述定义的表述就可以简洁地表示为：
<span class="math display">\[
\boldsymbol{\pi}^T=\boldsymbol{\pi}^T\cdot\boldsymbol{\mathcal{P}},\text{ or }\boldsymbol{\mathcal{P}}^T\cdot\boldsymbol{\pi}=\boldsymbol{\pi}
\]</span>
后一个式子可以说明<span class="math inline">\(\boldsymbol{\pi}\)</span>是矩阵<span class="math inline">\(\boldsymbol{\mathcal{P}}\)</span>​的特征值为1对应的特征向量。</p>
</div>
<div id="markov奖励过程的形式主义" class="section level3 hasAnchor" number="5.2.5">
<h3><span class="header-section-number">5.2.5</span> Markov奖励过程的形式主义<a href="causal.html#markov奖励过程的形式主义" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>我们之所以讲述Markov过程是因为希望通过为Markov过程添加增量特性来逐步进入Markov决策过程，也就是强化学习的算法框架。现在开始讲述介于二者之间的中间框架即Markov奖励过程。基本上我们只是为每次从一个状态转移到下一个状态时引入一个数值奖励的概念。这些奖励是随机的，我们需要做的就是在进行状态转移时指定这些奖励的概率分布。</p>
<p>Markov奖励过程的主要目的是计算如果让过程无限运行（期望从每个非终止状态获得的奖励总和）我们将累积多少奖励，考虑到未来的奖励需要适当地折现。</p>
<blockquote>
<p><strong>Def 3.8.1</strong></p>
<p>Markov奖励过程是一个Markov过程以及一个时间索引序列的奖励随机变量<span class="math inline">\(R_t\in\mathcal{D},\mathcal{D}\)</span>是<span class="math inline">\(\mathbb{R}\)</span>中一个可数子集，<span class="math inline">\(t=1,2,...,\)</span>满足Markov性质：
<span class="math display">\[
P[(R_{t+1},S_{t+1})|S_{t},S_{t-1},...,S_0]=P[(R_{t+1},S_{t+1})|S_t]\text{ for all }t\geq0
\]</span></p>
</blockquote>
<p>我们将<span class="math inline">\(P[(R_{t+1},S_{t+1})|S_t]\)</span>称为Markov Reward Process在时间<span class="math inline">\(t\)</span>地转移概率。由于我们通常假设Markov的时间齐次性，我们将假设MRP具有时间齐次性，即<span class="math inline">\(P[(R_{t+1},S_{t+1})|S_t]\)</span>与<span class="math inline">\(t\)</span>​无关。</p>
由时间齐次性的假设，MRP的转移概率可以表示为转移概率函数
<span class="math display">\[
\mathcal{P}_R:\mathcal{N\times D\times S}\rightarrow[0,1]
\]</span>
定义为
$$
<span class="math display">\[\begin{aligned}
&amp;\mathcal{P}_R(s,r,s&#39;)=P[(R_{t+1}=r,S_{t+1}=s&#39;)|S_t=s]\text{ for }t=0,1,2,...,\\
&amp;\text{for all }s\in\mathcal{N},r\in\mathcal{D},s&#39;\in\mathcal{S},\text{ s.t. }\sum_{s&#39;\in\mathcal{S}}\sum_{r\in\mathcal{D}}\mathcal{P}_R(s,r,s&#39;)=1,\text{ for all }s\in \mathcal{N}

\end{aligned}\]</span>
<p>$$
当涉及模拟时我们需要单独指定起始状态的概率分布。</p>
<p>现在可以扩展更多理论。给定奖励转移函数<span class="math inline">\(\mathcal{P}_R\)</span>，我们可以得到</p>
<ul>
<li><p>隐式Markov过程的概率转移函数<span class="math inline">\(P:\mathbb{N}\times S\rightarrow [0,1]\)</span>可以定义为
<span class="math display">\[
\mathcal{P}(s,s&#39;)=\sum_{r\in\mathcal{D}}\mathcal{P}_R(s,r,s&#39;)
\]</span></p></li>
<li><p>奖励转移函数<span class="math inline">\(\mathcal{R}_T:\mathcal{N\times S}\rightarrow \mathbb{R}\)</span>定义为
<span class="math display">\[
\mathcal{R}_T(s,s&#39;)=\mathbb{E}[R_{t+1}|S_{t+1}=s&#39;,S_t=s]=\sum_{r\in\mathcal{D}}\frac{\mathcal{P}_R(s,r,s&#39;)}{\mathcal{P}(s,s&#39;)}=\sum_{r\in\mathcal{D}}\frac{\mathcal{P}_R(s,r,s&#39;)}{\sum_{r\in\mathcal{D}}\mathcal{P}_R(s,r,s&#39;)}\cdot r
\]</span></p></li>
</ul>
<p>我们在实践中遇到的大多数MRP奖励规范可以直接表示为奖励转移函数<span class="math inline">\(\mathcal{R}_T\)</span>.最后我们想强调的是，可以将<span class="math inline">\(\mathcal{P}_R\)</span>或<span class="math inline">\(\mathcal{R}_T\)</span>转换为一种更紧凑的奖励函数。该函数足以执行涉及MRP的关键计算，这个奖励函数<span class="math inline">\(\mathcal{R}:\mathcal{N}\rightarrow \mathbb{R}\)</span>定义为
<span class="math display">\[
\mathcal{R}(s)=\mathbb{E}[R_{t+1}|S_t=s]=\sum_{s&#39;\in\mathcal{S}}\mathcal{P}(s,s&#39;)\cdot\mathcal{R}_T(s,s&#39;)=\sum_{s&#39;\in\mathcal{S}}\sum_{r\in\mathcal{D}}\mathcal{P}_R(s,r,s&#39;)\cdot r
\]</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="cdc.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["CBook.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
